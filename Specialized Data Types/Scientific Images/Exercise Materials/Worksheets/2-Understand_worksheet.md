# Understand Worksheet

## Understand the data (or try to)
<p>In this step, examine the dataset closely to understand what it is,
how the files interrelate, and what information is needed to reuse.
Common UNDERSTAND steps include:

- Check for quality assurance and usability issues such as missing
data, ambiguous headings, code execution failures, and data presentation
concerns
- Try to detect and extract any “hidden documentation” inherent to the
data files that may facilitate reuse or expose unintended
information
- Determine if the documentation of the data is sufficient for a user
with similar qualifications to the researcher’s to understand and reuse
the data. If not, recommend or create additional documentation (e.g., a
readme.txt template)

## Key Ethical Considerations

- If working with human data, is this research done with and
not on communities and populations involved?
- Are there labels or other descriptive indicators that could be
applied to better represent or protect an identified group of people
impacted by this dataset? (Example: <a
href="https://localcontexts.org/labels/traditional-knowledge-labels/"><u>TK
labels</u></a>)

## Essential Tasks

- Examine files, organization, and documentation more thoroughly. Are
there changes that could enhance the dataset?
- Are there missing data?
- Could a user with similar qualifications to the author’s understand
and reuse these data and reproduce the results?
- Are the data, documentation and/or metadata presented in a way that
aids in interpretation? (e.g., <a
href="https://deepblue.lib.umich.edu/data/Deep_Blue_Data_Example_Readme.txt"><u>readme
Example</u></a>)
- Is the context of the data explained? (Methodology information,
relevant citations, file relationships, etc.)
- Is the content of the data explained? (variable and value labels,
units of measurement, etc.)
- Are there file references/links to other files in the package (are
all the files there? Correctly referenced?)
- Is there additional documentation that may be helpful based on the
data type? (e.g., codebook, data dictionary, study protocol, survey
questionnaires (s), etc.)

Tasks vary based on file formats and subject domain. Sample tasks
based on format:

Tabular and text data questions:

- Check the organization of the data–is it well-structured?
- Are headers/codes clearly defined?
- Is quality control clearly defined?

- Is methodology clear and sufficient?

Scientific image(s) questions:

- Is proprietary software needed to view or manipulate the images?
- Is resolution high enough to be interpreted or useful?
- How do the image files relate to each other?
- How do the image files relate to other files in this dataset?

To view additional UNDERSTAND steps based on format, view the
following primers:

- <a
href="https://github.com/DataCurationNetwork/data-primers/blob/master/ISO%20Disk%20Image%20Primer/ISO-disk-image-primer.md"><u>ISO
Images</u></a> Primer
- <a href="http://hdl.handle.net/11299/210206"><u>Confocal Microscopy
Image</u></a> Primer
- <a
href="https://github.com/DataCurationNetwork/data-primers/blob/master/GeoTIFF%20Data%20Curation%20Primer/geotiff-data-curation-primer.md"><u>GeoTIFF</u></a>
Primer
- <a href="http://hdl.handle.net/2027.42/145724"><u>netCDF</u></a>
Primer and <a href="http://hdl.handle.net/11299/202825"><u>Tutorial
using NCAR dataset</u></a>
- <a
href="https://github.com/DataCurationNetwork/data-primers/blob/6109feaa21c677296636a434a414684193ecd171/Neuroimaging%20DICOM%20and%20NIfTI%20Data%20Curation%20Primer/neuroimaging-dicom-and-nifti-data-curation-primer.md"><u>Neuroimagining
and NICOM NIfTI</u></a> Primer

