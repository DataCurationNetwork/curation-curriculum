# <a name="_heading=h.w9klu5phc851"></a>Data Curation Network Lesson Plan: 
# <a name="_heading=h.iwfwnp9t11tx"></a>Curated Application for Scientific Images

<table>
<tr><th colspan="2" valign="top"><h2>Lesson Description</h2></th></tr>
<tr class="even">
<td><strong>Data Type</strong></td>
<td>Scientific Images</td>
</tr>
<tr class="odd">
<td><strong>Primary fields or areas of use</strong></td>
<td>All</td>
</tr>
<tr class="even">
<td><strong>Summary</strong></td>
<td><p>This workshop introduces basic concepts of curating scientific
images.</p>
<p>This workshop also provides an overview of the general CURATE(D)
curriculum.</p></td>
</tr>
<tr class="odd">
<td><strong>Estimated time</strong></td>
<td><em>3 hours (not including breaks)</em></td>
</tr>
<tr class="even">
<td><strong>Related primers</strong></td>
<td><p><a
href="https://github.com/DataCurationNetwork/data-primers/blob/master/Confocal%20Microscopy%20Images%20Data%20Curation%20Primer/confocal-microscopy-images-data-curation-primer.md"><u>Confocal
Microscopy Image Primer</u></a></p>
<p><a
href="https://github.com/DataCurationNetwork/data-primers/blob/master/GeoTIFF%20Data%20Curation%20Primer/geotiff-data-curation-primer.md"><u>GeoTIFF
Primer</u></a></p>
<p><a
href="https://github.com/DataCurationNetwork/data-primers/blob/master/Human%20Participants%20Data%20Essentials%20Data%20Curation%20Primer/human-participants-data-essentials-data-curation-primer.md"><u>Human
Participants Data Essentials Primer</u></a></p>
<p><a
href="https://github.com/DataCurationNetwork/data-primers/blob/master/Neuroimaging%20DICOM%20and%20NIfTI%20Data%20Curation%20Primer/neuroimaging-dicom-and-nifti-data-curation-primer.md"><u>Neuroimaging
DICOM and NIfTI Primer</u></a></p>
<p><a
href="https://github.com/DataCurationNetwork/data-primers/blob/master/CARE%20Primer/care-primer.md"><u>CARE
Data Principles, Indigenous data, Data related to Indigenous Peoples and
Interest</u></a></p></td>
</tr>
<tr class="odd">
<td><strong>Link to Slides</strong></td>
<td><u>Scientific Images Slide Deck</u></td>
</tr>
<tr class="even">
<td><strong>Date created</strong></td>
<td>June 2023</td>
</tr>
<tr class="odd">
<td><strong>Created by</strong></td>
<td><p>The Pixels:</p>
<p>Sarah J. Wright, Cornell University, <a
href="https://orcid.org/0000-0002-1502-131X"><u>https://orcid.org/0000-0002-1502-131X</u></a></p>
<p>Mariah Kenney, Carnegie Mellon University, <a
href="https://orcid.org/0000-0003-4884-108X"><u>https://orcid.org/0000-0003-4884-108X</u></a></p>
<p>Paul M. Gignac, University of Arizona, <a
href="https://orcid.org/0000-0001-9181-3258"><u>https://orcid.org/0000-0001-9181-3258</u></a></p>
<p>Amy Schuler, Cary Institute of Ecosystem Studies, <a
href="https://orcid.org/0000-0002-2459-2413"><u>https://orcid.org/0000-0002-2459-2413</u></a></p>
<p>Neggin Keshavarzian, Princeton University, <a
href="https://orcid.org/0000-0001-6753-1226"><u>https://orcid.org/0000-0001-6753-1226</u></a></p></td>
</tr>
</tbody>
</table>

<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="odd">
<td><h2 id="objectives-and-vocabulary">Objectives and
Vocabulary</h2></td>
</tr>
<tr class="even">
<td><p><strong>Learning Objectives:</strong></p>
<ul>
<li><p>Understand the steps of the DCN CURATED workflow.</p></li>
<li><p>Apply the CURATED workflow to a real-world image dataset</p></li>
<li><p>Through reflection and discussion, evaluate the CURATED
activities proposed in the workshop against those proposed by an
experienced curator</p></li>
</ul>
<p><strong>Terms to Know (organized alphabetically):</strong></p>
<ul>
<li><p><em>Data Curation Primers</em>: Data curation primers are <a
href="https://datacurationnetwork.org/outputs/data-curation-primers/"><u>peer-reviewed,
living documents</u></a> that detail a specific subject, disciplinary
area or curation task and that can be used as a reference to curate
research data.</p></li>
<li><p><em>Deep Blue Data</em>: a repository offered by the University
of Michigan Library that provides access and preservation services for
digital research data that were developed or used in the support of
research activities at U-M.</p></li>
<li><p><em>Lossless file format</em>: File compression in which file
size is reduced without losing data or quality from the original file.
When a lossless file is uncompressed, it is identical to the original
file before compression (e.g., PNG, TIFF, RAW files).</p></li>
<li><p><em>Lossy file format</em>: File compression in which file size
is reduced by permanently eliminating some amount of information,
especially redundant or less important data. This process results in
some loss of quality compared to the original file (e.g., JPEG
files)</p></li>
<li><p><em>Pixel</em>: The smallest unit of a 2D image, representing
brightness and/or color. The width and length of a pixel may correspond
to physical measurements of distance.</p></li>
<li><p><em>Raster</em>: A type of digital image (e.g., in PNG or TIFF
file format) that is composed of a discrete grid of pixels corresponding
to specific picture elements. Raster images have inherent limitations
when it comes to size scaling due to their pixel-based nature (in
contrast to <em>vector</em>.)</p></li>
<li><p><em>Scientific Images</em>: Visual representations of recorded
factual material, 1) composed of a finite number of elements with a
particular location and value, and 2) commonly accepted in the
scientific community as of sufficient quality to validate and replicate
research findings.</p></li>
<li><p><em>Small</em>: A peer-reviewed and primary research-focused
scientific journal addressing nano/micro-scale materials and phenomena.
With a 2021 Journal Impact Factor of 15, <em>Small</em> continues to be
among the top multidisciplinary journals covering a broad spectrum of
topics at the nano- and microscale at the interface of materials
science, chemistry, physics, engineering, medicine, and
biology.</p></li>
<li><p><em>Vector:</em> A type of digital image (e.g.,in EPS file
format) that is composed of mathematical equations used to represent
picture elements. The equations define discrete paths that create simple
geometric shapes (e.g., points, lines, curves, circles, and polygons)
and complex images. Vector images can be size scaled without losing
quality.</p></li>
<li><p><em>Voxel:</em> The smallest unit of a 3D volume, representing
brightness and/or color (i.e., a “3D pixel”). The width, length, and
depth of a voxel may correspond to physical measurements of
distance.</p></li>
<li><p><em>Z-stack:</em> A series of 2D images, each with X and Y
dimensions, aligned along a third axis of depth (the Z-axis). This
alignment forms a coherent sequence, creating a 3D representation by
adding volume information to traditionally flat X and Y axes.</p></li>
</ul>
<p>See <a
href="https://www.pearson.com/en-gb/subject-catalog/p/digital-image-processing-global-edition/P200000004313/9781292223070"><u>this
resource</u></a> for further scientific imaging terminology and
definitions.</p></td>
</tr>
</tbody>
</table>

<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="odd">
<td><h2 id="datasets-for-lesson">Dataset(s) for Lesson</h2></td>
</tr>
<tr class="even">
<td><p><strong>Required Tools/Software:</strong></p>
<ul>
<li><p>Web browser</p></li>
<li><p>text editing software</p></li>
<li><p>ImageJ (a.k.a., FIJI)</p></li>
</ul>
<ul>
<li><p>Instructions can be found in “Pre-Work” document</p></li>
</ul>
<p><strong>Dataset Citations:</strong></p>
<ul>
<li><p><mark>Moniri, S., Bale, H., Volkenandt, T., Wang, Y., Gao, J.,
Lu, T., Sun, K., Shahani, A. J. (2020). <em>Dataset for 'Multi‑Step
Crystallization of Self‑Organized Spiral Eutectics'</em> [Data set],
University of Michigan - Deep Blue Data. <a
href="https://doi.org/10.7302/day1-6d63"><u>https://doi.org/10.7302/day1-6d63</u></a></mark></p></li>
</ul></td>
</tr>
</tbody>
</table>

<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="odd">
<td><h2 id="outline-and-content">Outline and Content</h2></td>
</tr>
<tr class="even">
<td><ol type="I">
<li><p><em>Introduction</em></p>
<ol type="A">
<li><p><em>Aims</em></p></li>
<li><p><em>Curator Log</em></p></li>
<li><p><em>What are scientific images?</em></p></li>
<li><p><em>Software Roundup &amp; Get ImageJ Running</em></p></li>
</ol></li>
<li><p><em>Check</em></p>
<ol type="A">
<li><p><em>Introduce Check Worksheet</em></p></li>
<li><p><em>Activity: file format, general requirements</em></p></li>
</ol></li>
<li><p><em>Understand</em></p>
<ol type="A">
<li><p><em>Introduction to Understand step</em></p></li>
<li><p><em>Think-pair-share activity</em></p>
<ol type="1">
<li><p><em>Review of questions needed to understand data</em></p>
<ol type="a">
<li><p><em>Share out 1 :</em></p>
<ol type="1">
<li><p><em>Did the data pass the Check step?</em></p></li>
</ol></li>
</ol></li>
<li><p><em>Digging Deeper</em></p>
<ol type="a">
<li><p><em>Share out 2:</em></p>
<ol type="1">
<li><p><em>What didn’t you understand about the dataset?</em></p></li>
</ol></li>
</ol></li>
</ol></li>
</ol></li>
<li><p><em>Request</em></p>
<ol type="A">
<li><p><em>Introduce the Request step</em></p></li>
<li><p><em>Example Request step email template</em></p></li>
<li><p><em>Request step Activity</em></p>
<ol type="1">
<li><p><em>Group role-play activity &amp; report back;
*or*</em></p></li>
<li><p><em>Group AI activity &amp; report back</em></p></li>
</ol></li>
</ol></li>
<li><p><em>Augment</em></p>
<ol type="A">
<li><p><em>Introduction</em></p></li>
<li><p><em>What is metadata?</em></p></li>
<li><p><em>Considerations</em></p></li>
</ol></li>
<li><p><em>Transformation</em></p>
<ol type="A">
<li><p><em>Introduction with example</em></p></li>
<li><p><em>Transformation activity &amp; group discussion</em></p></li>
</ol></li>
<li><p><em>Evaluate</em></p></li>
</ol>
<ol type="A">
<li><p><em>Introduction to FAIR &amp; CARE</em></p></li>
<li><p><em>Evaluate exercise</em></p></li>
</ol>
<ol start="8" type="I">
<li><p><em>Document</em></p>
<ol type="A">
<li><p><em>Group Discussion about Curator Log contents</em></p></li>
</ol></li>
<li><p><em>Review and Summary</em></p>
<ol type="A">
<li><p><em>Questions</em></p></li>
</ol></li>
</ol></td>
</tr>
<tr class="odd">
<td><h3 id="introduction">Introduction</h3></td>
</tr>
<tr class="even">
<td><p><strong>Mode(s):</strong> <em>Lecture</em></p>
<p><strong>Estimated time<em>: </em></strong><em>15 minutes</em></p>
<p>Describe aims of the workshop, introduce the curator log, define and
describe what scientific images are and review important software to
view and manipulate images.</p></td>
</tr>
<tr class="odd">
<td><h3 id="check-step">Check Step </h3></td>
</tr>
<tr class="even">
<td><p><strong>Mode(s):</strong> <em>Lecture, activity and small group
discussion</em></p>
<p><strong>Estimated time<em>: </em></strong><em>30 minutes</em></p>
<p><em>Checking</em> the data is the first step to determining if what
has been submitted is curatable.</p>
<p>Lecture will introduce the steps to check files, then there will be a
short activity and small group discussion about checking file format -
(e.g., corrupt file, open-access file), and comparing different required
fields for generalist vs. specialized repositories. Is the data
appropriate to be shared?</p>
<p>Please use the worksheet <a
href="https://docs.google.com/document/d/18SNQdQqgu8DCLlcDzmDQGATHlJMZLqkxAyD4yoRL0HM/edit?usp=sharing"><u>here</u></a>
to assist with the activity.</p></td>
</tr>
<tr class="odd">
<td><h3 id="understand-step">Understand Step</h3></td>
</tr>
<tr class="even">
<td><p><strong>Mode(s):</strong> <em>Lecture, small group
discussion</em></p>
<p><strong>Estimated time:</strong> <em>20 minutes</em></p>
<p><em>Understanding</em> the data is an important step to ensure that
the data content, context, and quality can be described accurately and
precisely for someone else. Small group discussions will be used to
determine what information is missing from the Deep Blue Data entry.
Each participant will come up with a list of up to five questions that
they have based on their attempt to understand the data. A question may
be as straightforward as, “how are .CTF files read?”. Alternatively, a
question may be as complex as, “how do the included .PNG files relate to
each other spatially, if at all?”.</p>
<p>-</p>
<p>Group members will compile a list of their questions, and then divide
up the list to search for answers. Answers should be referenced, and
answers that cannot be found should be tallied for the Request step.
Please use the worksheet <a
href="https://docs.google.com/document/d/1M58F8LgI-S6XtusuwZLfwZ2sNTsVmu7Pg7Ce3KprfCo/edit?usp=sharing"><u>here</u></a>
to assist with the activity.</p>
<p>Please save the list of questions and answers for the
Documentation.</p></td>
</tr>
<tr class="odd">
<td><h3 id="request-step">Request Step</h3></td>
</tr>
<tr class="even">
<td><p><strong>Mode(s):</strong> <em>Lecture, activity and small group
discussion</em></p>
<p><strong>Estimated time:</strong> <em>20-25 minutes</em></p>
<p><em>Requesting</em> additional information is an important mechanism
to ensure that the data will pass additional quality checks.</p>
<p>Consider using a <a
href="https://www.lucidmeetings.com/glossary/plus-delta"><u>plus-delta</u></a>
model of requesting information by describing what content was helpful,
and requesting additional information that enhances the dataset’s
accessibility.</p>
<p>A useful approach for this step is to refer to which questions from
the <em>Understand</em> step either 1) cannot be answered with
documentation available, and/or 2) require additional confirmation to
ensure the specific, relevant, and complete. These constitute targets
for <em>Request</em>. The group members should now draft a communication
with the data submitter requesting missing information identified
previously, using the Request more information letter (a completed
example/template letter <a
href="https://docs.google.com/document/d/1anCUbR51lmyAg1hpJAv_IjXQGcnYeduREHiy0N7kKe0/edit?usp=sharing"><u>here</u></a>).</p></td>
</tr>
<tr class="odd">
<td><h3 id="augment-step">Augment Step</h3></td>
</tr>
<tr class="even">
<td><p><strong>Mode(s):</strong> <em>Lecture, discussion</em></p>
<p><strong>Estimated time:</strong> <em>15 minutes</em></p>
<p><em>Augmenting</em> the original dataset submitted is how incomplete
submissions become curatable. This step includes appreciating metadata
relevant to the submission.</p>
<p>Small groups will examine the information gathered in the Understand
and Request steps of the CURATED workflow. Participants will parse these
for the “missing pieces” previously identified in the Understand step.
Working collaboratively, the participants of each group will determine
how and where to augment the dataset metadata and documentation to
include the missing elements. Please use the worksheet <a
href="https://docs.google.com/document/d/1kTO_UAGjJeSGeGqb1nzZttQ1t-y_GCmiTF4y948c1Ck/edit?usp=sharing"><u>here</u></a>
to assist with the activity.</p></td>
</tr>
<tr class="odd">
<td><h3 id="transformation-step">Transformation Step</h3></td>
</tr>
<tr class="even">
<td><p><strong>Mode(s):</strong> <em>Lecture, activity, small group
discussion</em></p>
<p><strong>Estimated time:</strong> <em>35 minutes</em></p>
<p><em>Transforming</em> data into widely accessible formats ensures
that the curated dataset can be maximally utilized. Lecture on
file-format transformation and transformation activity. Participants
will transform the image datasets, examine the changes made to the data,
and discuss the implications of the transformation for curation and data
sharing.</p>
<p>In this step, consider the file formats in the dataset to make them
more interoperable, reusable, preservation friendly, and non-proprietary
when possible.<sup>1</sup></p>
<p>Common TRANSFORM steps include:</p>
<ul>
<li><p>Identify specialized file formats and their restrictions (e.g.,
Is the software freely available? If so, link to it or archive it
alongside the data)</p></li>
<li><p>Propose open source or more reusable formats when appropriate
(e.g., TIFF (uncompressed), JPEG2000 (lossless) (*.jp2), or PNG
(*.png))</p></li>
<li><p>Retain original file formats</p></li>
</ul>
<p><sup>1</sup> See Cornell’s list of preservation format
recommendations: <a
href="http://guides.library.cornell.edu/ecommons/formats"><u>http://guides.library.cornell.edu/ecommons/formats</u></a></p>
<p>Library of Congress - Sustainability of Digital Formats:</p>
<p><a
href="https://www.loc.gov/preservation/digital/formats/content/still.shtml"><u>https://www.loc.gov/preservation/digital/formats/content/still.shtml</u></a></p>
<p>Use the worksheets here for transformation activities:</p>
<p>Complete activity on your own: <a
href="https://docs.google.com/document/u/0/d/1Ip420S9vQbaeA8toZWvIFoZCnEmrVAWUy5_ZXNWsLfc/edit"><u>5-Transform_worksheet_no_results</u></a></p>
<p>Follow along: <a
href="https://docs.google.com/document/u/0/d/1souFAHdXsaDW6ZbnaffR4YKYVJsJiv1cv1bzWLEDuQ4/edit"><u>5-Transform_worksheet</u></a></p></td>
</tr>
<tr class="odd">
<td><h3 id="evaluate-step">Evaluate Step</h3></td>
</tr>
<tr class="even">
<td><p><strong>Mode:</strong> <em>Lecture, small group
discussion</em></p>
<p><strong>Estimated time<em>: </em></strong><em>15 minutes</em></p>
<p><em>Evaluating</em> the dataset ensures that space for
self-reflection on the augmented and transformed data submission is in
place.</p>
<p>This will include a short overview of FAIR and CARE, then short
group/table discussions evaluating the spiral eutectics dataset
according to the FAIR checklist, and whether the CARE Principles apply
to this dataset (or may apply to scientific image data in general).</p>
<p>Use <a
href="https://docs.google.com/document/d/1AkkuiO0bfBPCu-ofY8FLEKm07aVqyeI93rpAOv2aJaY/edit"><u>6-Evaluate_discussion</u></a>
to guide your discussions.</p></td>
</tr>
<tr class="odd">
<td>Document Step</td>
</tr>
<tr class="even">
<td><p><strong>Mode:</strong> <em>Whole room discussion</em></p>
<p><strong>Estimated time<em>:</em></strong> <em>10-15 minutes</em></p>
<p>A whole room discussion about the documentation process. Please
revisit your curator log.</p></td>
</tr>
</tbody>
</table>

<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="odd">
<td><h2 id="additional-resources">Additional Resources </h2></td>
</tr>
<tr class="even">
<td><p><strong>Bibliography</strong></p>
<blockquote>
<p>Bray, M.-A., S.M. Gustafsdottir, M.H. Rohban, S. Singh, V. Ljosa,
K.L. Sokolnicki, J.A. Bittker, et al. “A Dataset of Images and
Morphological Profiles of 30 000 Small-Molecule Treatments Using the
Cell Painting Assay.” <em>GigaScience</em> 6, no. 12 (2017): 1–5. <a
href="https://doi.org/10.1093/gigascience/giw014"><u>https://doi.org/10.1093/gigascience/giw014</u></a>.</p>
<p>Driscoll, M.K., and A. Zaritsky. “Data Science in Cell Imaging.”
<em>Journal of Cell Science</em> 134, no. 7 (2021). <a
href="https://doi.org/10.1242/jcs.254292"><u>https://doi.org/10.1242/jcs.254292</u></a>.</p>
<p>Goldberg, I.G., Allan, C., Burel, JM. et al. The Open Microscopy
Environment (OME) Data Model and XML file: open tools for informatics
and quantitative analysis in biological imaging. Genome Biol 6, R47
(2005). <a
href="https://doi.org/10.1186/gb-2005-6-5-r47"><u>https://doi.org/10.1186/gb-2005-6-5-r47</u></a></p>
<p>Gonzalez, R.C. and Woods, R.E. <em>Digital Image Processing</em>,
Global Edition, 4th Edition. Pearson (2018) <a
href="https://www.pearson.com/en-gb/subject-catalog/p/digital-image-processing-global-edition/P200000004313/9781292223070"><u>https://www.pearson.com/en-gb/subject-catalog/p/digital-image-processing-global-edition/P200000004313/9781292223070</u></a></p>
<p>Gonzalez-Beltran, A.N., P. Masuzzo, C. Ampe, G.-J. Bakker, S. Besson,
R.H. Eibl, P. Friedl, et al. “Community Standards for Open Cell
Migration Data.” <em>GigaScience</em> 9, no. 5 (2020). <a
href="https://doi.org/10.1093/gigascience/giaa041"><u>https://doi.org/10.1093/gigascience/giaa041</u></a>.</p>
<p>Linkert, M., C.T. Rueden, C. Allan, J.-M. Burel, W. Moore, A.
Patterson, B. Loranger, et al. “Metadata Matters: Access to Image Data
in the Real World.” <em>Journal of Cell Biology</em> 189, no. 5 (2010):
777–82. <a
href="https://doi.org/10.1083/jcb.201004104"><u>https://doi.org/10.1083/jcb.201004104</u></a>.</p>
<p>Marmo, C., T.M. Hare, S. Erard, M. Minin, F.-X. Pineau, A. Zinzi, B.
Cecconi, and A.P. Rossi. “FITS Format for Planetary Surfaces:
Definitions, Applications, and Best Practices.” <em>Earth and Space
Science</em> 5, no. 10 (2018): 640–51. <a
href="https://doi.org/10.1029/2018EA000388"><u>https://doi.org/10.1029/2018EA000388</u></a>.</p>
<p>Pence, W.D., L. Chiappetti, C.G. Page, R.A. Shaw, and E. Stobie.
“Definition of the Flexible Image Transport System (FITS), Version 3.0.”
<em>Astronomy and Astrophysics</em> 524, no. 10 (2010). <a
href="https://doi.org/10.1051/0004-6361/201015362"><u>https://doi.org/10.1051/0004-6361/201015362</u></a>.</p>
<p>Piovesan, A., V. Vancauwenberghe, T. Van De Looverbosch, P. Verboven,
and B. Nicolaï. “X-Ray Computed Tomography for 3D Plant Imaging.”
<em>Trends in Plant Science</em> 26, no. 11 (2021): 1171–85. <a
href="https://doi.org/10.1016/j.tplants.2021.07.010"><u>https://doi.org/10.1016/j.tplants.2021.07.010</u></a>.</p>
<p><mark>Sarkans, U., Chiu, W., Collinson, L. <em>et al.</em> REMBI:
Recommended Metadata for Biological Images—enabling reuse of microscopy
data in biology. <em>Nat Methods</em> 18, 1418–1422 (2021). <a
href="https://doi.org/10.1038/s41592-021-01166-8"><u>https://doi.org/10.1038/s41592-021-01166-8</u></a></mark></p>
<p>Williams, E., J. Moore, S.W. Li, G. Rustici, A. Tarkowska, A.
Chessel, S. Leo, et al. “Image Data Resource: A Bioimage Data
Integration and Publication Platform.” <em>Nature Methods</em> 14, no. 8
(2017): 775–81. <a
href="https://doi.org/10.1038/nmeth.4326"><u>https://doi.org/10.1038/nmeth.4326</u></a>.</p>
<p>Wilson, S.L., G.P. Way, W. Bittremieux, J.-P. Armache, M.A. Haendel,
and M.M. Hoffman. “Sharing Biological Data: Why, When, and How.”
<em>FEBS Letters</em> 595, no. 7 (2021): 847–63. <a
href="https://doi.org/10.1002/1873-3468.14067"><u>https://doi.org/10.1002/1873-3468.14067</u></a>.</p>
<p>Zaritsky, A. “Sharing and Reusing Cell Image Data.” <em>Molecular
Biology of the Cell</em> 29, no. 11 (2018): 1274–80. <a
href="https://doi.org/10.1091/mbc.E17-10-0606"><u>https://doi.org/10.1091/mbc.E17-10-0606</u></a>.</p>
</blockquote>
<p><strong>Other Resources</strong></p>
<blockquote>
<p><a
href="https://carpentries.org/blog/2023/01/dc-image-processing-stable-release/"><u>Data
Carpentry: Image Processing with Python</u></a></p>
</blockquote></td>
</tr>
</tbody>
</table>
